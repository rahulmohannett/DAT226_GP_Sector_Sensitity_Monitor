[2025-12-02T22:49:58.673+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-12-02T22:49:58.680+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: market_data_ingest.ensure_objects manual__2025-12-02T22:49:57.145720+00:00 [queued]>
[2025-12-02T22:49:58.683+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: market_data_ingest.ensure_objects manual__2025-12-02T22:49:57.145720+00:00 [queued]>
[2025-12-02T22:49:58.683+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 2
[2025-12-02T22:49:58.687+0000] {taskinstance.py:2888} INFO - Executing <Task(SnowflakeOperator): ensure_objects> on 2025-12-02 22:49:57.145720+00:00
[2025-12-02T22:49:58.691+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=240) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-12-02T22:49:58.691+0000] {standard_task_runner.py:72} INFO - Started process 243 to run task
[2025-12-02T22:49:58.691+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'market_data_ingest', 'ensure_objects', 'manual__2025-12-02T22:49:57.145720+00:00', '--job-id', '142', '--raw', '--subdir', 'DAGS_FOLDER/market_data_ingest.py', '--cfg-path', '/tmp/tmp7wgg5fst']
[2025-12-02T22:49:58.692+0000] {standard_task_runner.py:105} INFO - Job 142: Subtask ensure_objects
[2025-12-02T22:49:58.708+0000] {task_command.py:467} INFO - Running <TaskInstance: market_data_ingest.ensure_objects manual__2025-12-02T22:49:57.145720+00:00 [running]> on host 3a991512098d
[2025-12-02T22:49:58.840+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='data' AIRFLOW_CTX_DAG_ID='market_data_ingest' AIRFLOW_CTX_TASK_ID='ensure_objects' AIRFLOW_CTX_EXECUTION_DATE='2025-12-02T22:49:57.145720+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-12-02T22:49:57.145720+00:00'
[2025-12-02T22:49:58.841+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-12-02T22:49:58.845+0000] {sql.py:266} INFO - Executing: ['create schema if not exists "USER_DB_OSTRICH"."RAW"', 'create table if not exists "USER_DB_OSTRICH"."RAW"."MARKET_DATA" (SYMBOL string, DATE date, OPEN float, CLOSE float, LOW float, HIGH float, VOLUME number)', 'create table if not exists "USER_DB_OSTRICH"."RAW"."MARKET_DATA_STAGE" (SYMBOL string, DATE date, OPEN float, CLOSE float, LOW float, HIGH float, VOLUME number)']
[2025-12-02T22:49:58.848+0000] {base.py:84} INFO - Retrieving connection 'snowflake_conn'
[2025-12-02T22:49:58.851+0000] {base.py:84} INFO - Retrieving connection 'snowflake_conn'
[2025-12-02T22:49:58.851+0000] {connection.py:413} INFO - Snowflake Connector for Python Version: 3.12.1, Python Version: 3.12.5, Platform: Linux-6.10.14-linuxkit-aarch64-with-glibc2.36
[2025-12-02T22:49:58.851+0000] {connection.py:1196} INFO - Connecting to GLOBAL Snowflake domain
[2025-12-02T22:49:58.851+0000] {connection.py:1277} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-12-02T22:50:00.556+0000] {cursor.py:1156} INFO - Number of results in first chunk: 1
[2025-12-02T22:50:00.557+0000] {sql.py:509} INFO - Running statement: create schema if not exists "USER_DB_OSTRICH"."RAW", parameters: None
[2025-12-02T22:50:00.678+0000] {cursor.py:1156} INFO - Number of results in first chunk: 1
[2025-12-02T22:50:00.679+0000] {sql.py:518} INFO - Rows affected: 1
[2025-12-02T22:50:00.681+0000] {snowflake.py:422} INFO - Rows affected: 1
[2025-12-02T22:50:00.681+0000] {snowflake.py:423} INFO - Snowflake query id: 01c0ca5a-0307-2a55-000f-c0df00a90292
[2025-12-02T22:50:00.682+0000] {sql.py:509} INFO - Running statement: create table if not exists "USER_DB_OSTRICH"."RAW"."MARKET_DATA" (SYMBOL string, DATE date, OPEN float, CLOSE float, LOW float, HIGH float, VOLUME number), parameters: None
[2025-12-02T22:50:01.030+0000] {cursor.py:1156} INFO - Number of results in first chunk: 1
[2025-12-02T22:50:01.032+0000] {sql.py:518} INFO - Rows affected: 1
[2025-12-02T22:50:01.033+0000] {snowflake.py:422} INFO - Rows affected: 1
[2025-12-02T22:50:01.033+0000] {snowflake.py:423} INFO - Snowflake query id: 01c0ca5a-0307-2a4d-000f-c0df00a8a69e
[2025-12-02T22:50:01.034+0000] {sql.py:509} INFO - Running statement: create table if not exists "USER_DB_OSTRICH"."RAW"."MARKET_DATA_STAGE" (SYMBOL string, DATE date, OPEN float, CLOSE float, LOW float, HIGH float, VOLUME number), parameters: None
[2025-12-02T22:50:01.152+0000] {cursor.py:1156} INFO - Number of results in first chunk: 1
[2025-12-02T22:50:01.152+0000] {sql.py:518} INFO - Rows affected: 1
[2025-12-02T22:50:01.153+0000] {snowflake.py:422} INFO - Rows affected: 1
[2025-12-02T22:50:01.153+0000] {snowflake.py:423} INFO - Snowflake query id: 01c0ca5a-0307-2a4d-000f-c0df00a8a6a2
[2025-12-02T22:50:01.233+0000] {cursor.py:1156} INFO - Number of results in first chunk: 1
[2025-12-02T22:50:01.235+0000] {connection.py:788} INFO - closed
[2025-12-02T22:50:01.294+0000] {connection.py:794} INFO - No async queries seem to be running, deleting session
[2025-12-02T22:50:01.564+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-12-02T22:50:01.565+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=market_data_ingest, task_id=ensure_objects, run_id=manual__2025-12-02T22:49:57.145720+00:00, execution_date=20251202T224957, start_date=20251202T224958, end_date=20251202T225001
[2025-12-02T22:50:01.606+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-12-02T22:50:01.618+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/models/baseoperator.py:1378 AirflowProviderDeprecationWarning: Call to deprecated class SnowflakeOperator. (This class is deprecated. Please use `***.providers.common.sql.operators.sql.SQLExecuteQueryOperator`. Also, you can provide `hook_params={'warehouse': <warehouse>, 'database': <database>, 'role': <role>, 'schema': <schema>, 'authenticator': <authenticator>,'session_parameters': <session_parameters>}`.)
[2025-12-02T22:50:01.631+0000] {taskinstance.py:3900} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-12-02T22:50:01.635+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
