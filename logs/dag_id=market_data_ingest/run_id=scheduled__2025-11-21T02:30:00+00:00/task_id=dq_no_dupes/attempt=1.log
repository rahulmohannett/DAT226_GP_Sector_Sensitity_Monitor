[2025-11-22T02:43:16.191+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-11-22T02:43:16.197+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: market_data_ingest.dq_no_dupes scheduled__2025-11-21T02:30:00+00:00 [queued]>
[2025-11-22T02:43:16.202+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: market_data_ingest.dq_no_dupes scheduled__2025-11-21T02:30:00+00:00 [queued]>
[2025-11-22T02:43:16.202+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 2
[2025-11-22T02:43:16.207+0000] {taskinstance.py:2888} INFO - Executing <Task(PythonOperator): dq_no_dupes> on 2025-11-21 02:30:00+00:00
[2025-11-22T02:43:16.211+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=3592) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-11-22T02:43:16.212+0000] {standard_task_runner.py:72} INFO - Started process 3595 to run task
[2025-11-22T02:43:16.211+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'market_data_ingest', 'dq_no_dupes', 'scheduled__2025-11-21T02:30:00+00:00', '--job-id', '49', '--raw', '--subdir', 'DAGS_FOLDER/market_data_ingest.py', '--cfg-path', '/tmp/tmpbdfm3tt7']
[2025-11-22T02:43:16.213+0000] {standard_task_runner.py:105} INFO - Job 49: Subtask dq_no_dupes
[2025-11-22T02:43:16.233+0000] {task_command.py:467} INFO - Running <TaskInstance: market_data_ingest.dq_no_dupes scheduled__2025-11-21T02:30:00+00:00 [running]> on host 663ef6e4cd5f
[2025-11-22T02:43:16.376+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='data' AIRFLOW_CTX_DAG_ID='market_data_ingest' AIRFLOW_CTX_TASK_ID='dq_no_dupes' AIRFLOW_CTX_EXECUTION_DATE='2025-11-21T02:30:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-11-21T02:30:00+00:00'
[2025-11-22T02:43:16.376+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-11-22T02:43:16.386+0000] {base.py:84} INFO - Retrieving connection 'snowflake_conn'
[2025-11-22T02:43:16.386+0000] {connection.py:413} INFO - Snowflake Connector for Python Version: 3.12.1, Python Version: 3.12.5, Platform: Linux-6.10.14-linuxkit-aarch64-with-glibc2.36
[2025-11-22T02:43:16.387+0000] {connection.py:1196} INFO - Connecting to GLOBAL Snowflake domain
[2025-11-22T02:43:16.387+0000] {connection.py:1277} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-11-22T02:43:17.218+0000] {cursor.py:1156} INFO - Number of results in first chunk: 1
[2025-11-22T02:43:17.740+0000] {cursor.py:1156} INFO - Number of results in first chunk: 1
[2025-11-22T02:43:18.116+0000] {cursor.py:1156} INFO - Number of results in first chunk: 1
[2025-11-22T02:43:18.118+0000] {logging_mixin.py:190} INFO - [DQ] total_rows=360 distinct_pairs=360
[2025-11-22T02:43:18.119+0000] {connection.py:788} INFO - closed
[2025-11-22T02:43:18.246+0000] {connection.py:794} INFO - No async queries seem to be running, deleting session
[2025-11-22T02:43:18.422+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-11-22T02:43:18.428+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-11-22T02:43:18.429+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=market_data_ingest, task_id=dq_no_dupes, run_id=scheduled__2025-11-21T02:30:00+00:00, execution_date=20251121T023000, start_date=20251122T024316, end_date=20251122T024318
[2025-11-22T02:43:18.466+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-11-22T02:43:18.477+0000] {taskinstance.py:3900} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-11-22T02:43:18.478+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-11-22T18:33:48.845+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-11-22T18:33:48.850+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: market_data_ingest.dq_no_dupes scheduled__2025-11-21T02:30:00+00:00 [queued]>
[2025-11-22T18:33:48.852+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: market_data_ingest.dq_no_dupes scheduled__2025-11-21T02:30:00+00:00 [queued]>
[2025-11-22T18:33:48.852+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 2
[2025-11-22T18:33:48.856+0000] {taskinstance.py:2888} INFO - Executing <Task(PythonOperator): dq_no_dupes> on 2025-11-21 02:30:00+00:00
[2025-11-22T18:33:48.859+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=429) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-11-22T18:33:48.860+0000] {standard_task_runner.py:72} INFO - Started process 432 to run task
[2025-11-22T18:33:48.860+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'market_data_ingest', 'dq_no_dupes', 'scheduled__2025-11-21T02:30:00+00:00', '--job-id', '9', '--raw', '--subdir', 'DAGS_FOLDER/market_data_ingest.py', '--cfg-path', '/tmp/tmph5iczyhe']
[2025-11-22T18:33:48.861+0000] {standard_task_runner.py:105} INFO - Job 9: Subtask dq_no_dupes
[2025-11-22T18:33:48.972+0000] {task_command.py:467} INFO - Running <TaskInstance: market_data_ingest.dq_no_dupes scheduled__2025-11-21T02:30:00+00:00 [running]> on host 599ab64e91dc
[2025-11-22T18:33:48.995+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='data' AIRFLOW_CTX_DAG_ID='market_data_ingest' AIRFLOW_CTX_TASK_ID='dq_no_dupes' AIRFLOW_CTX_EXECUTION_DATE='2025-11-21T02:30:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-11-21T02:30:00+00:00'
[2025-11-22T18:33:48.995+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-11-22T18:33:49.003+0000] {base.py:84} INFO - Retrieving connection 'snowflake_conn'
[2025-11-22T18:33:49.003+0000] {connection.py:413} INFO - Snowflake Connector for Python Version: 3.12.1, Python Version: 3.12.5, Platform: Linux-6.10.14-linuxkit-aarch64-with-glibc2.36
[2025-11-22T18:33:49.004+0000] {connection.py:1196} INFO - Connecting to GLOBAL Snowflake domain
[2025-11-22T18:33:49.004+0000] {connection.py:1277} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-11-22T18:33:49.607+0000] {cursor.py:1156} INFO - Number of results in first chunk: 1
[2025-11-22T18:33:49.704+0000] {cursor.py:1156} INFO - Number of results in first chunk: 1
[2025-11-22T18:33:50.093+0000] {cursor.py:1156} INFO - Number of results in first chunk: 1
[2025-11-22T18:33:50.094+0000] {logging_mixin.py:190} INFO - [DQ] total_rows=2160 distinct_pairs=2160
[2025-11-22T18:33:50.095+0000] {connection.py:788} INFO - closed
[2025-11-22T18:33:50.161+0000] {connection.py:794} INFO - No async queries seem to be running, deleting session
[2025-11-22T18:33:50.229+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-11-22T18:33:50.244+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-11-22T18:33:50.244+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=market_data_ingest, task_id=dq_no_dupes, run_id=scheduled__2025-11-21T02:30:00+00:00, execution_date=20251121T023000, start_date=20251122T183348, end_date=20251122T183350
[2025-11-22T18:33:50.295+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-11-22T18:33:50.394+0000] {taskinstance.py:3900} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-11-22T18:33:50.395+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-11-22T22:29:35.932+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-11-22T22:29:35.937+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: market_data_ingest.dq_no_dupes scheduled__2025-11-21T02:30:00+00:00 [queued]>
[2025-11-22T22:29:35.940+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: market_data_ingest.dq_no_dupes scheduled__2025-11-21T02:30:00+00:00 [queued]>
[2025-11-22T22:29:35.940+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 2
[2025-11-22T22:29:35.943+0000] {taskinstance.py:2888} INFO - Executing <Task(SnowflakeOperator): dq_no_dupes> on 2025-11-21 02:30:00+00:00
[2025-11-22T22:29:35.946+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=478) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-11-22T22:29:35.947+0000] {standard_task_runner.py:72} INFO - Started process 490 to run task
[2025-11-22T22:29:35.947+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'market_data_ingest', 'dq_no_dupes', 'scheduled__2025-11-21T02:30:00+00:00', '--job-id', '9', '--raw', '--subdir', 'DAGS_FOLDER/market_data_ingest.py', '--cfg-path', '/tmp/tmpllcvbc6d']
[2025-11-22T22:29:35.948+0000] {standard_task_runner.py:105} INFO - Job 9: Subtask dq_no_dupes
[2025-11-22T22:29:35.962+0000] {task_command.py:467} INFO - Running <TaskInstance: market_data_ingest.dq_no_dupes scheduled__2025-11-21T02:30:00+00:00 [running]> on host 1d97c0704ad8
[2025-11-22T22:29:35.984+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='data' AIRFLOW_CTX_DAG_ID='market_data_ingest' AIRFLOW_CTX_TASK_ID='dq_no_dupes' AIRFLOW_CTX_EXECUTION_DATE='2025-11-21T02:30:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-11-21T02:30:00+00:00'
[2025-11-22T22:29:35.985+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-11-22T22:29:35.989+0000] {sql.py:266} INFO - Executing: select count(*) from (select SYMBOL, DATE from "USER_DB_OSTRICH"."RAW"."MARKET_DATA" group by 1,2 having count(*) > 1) having count(*) = 0
[2025-11-22T22:29:35.993+0000] {base.py:84} INFO - Retrieving connection 'snowflake_conn'
[2025-11-22T22:29:35.995+0000] {base.py:84} INFO - Retrieving connection 'snowflake_conn'
[2025-11-22T22:29:35.996+0000] {connection.py:413} INFO - Snowflake Connector for Python Version: 3.12.1, Python Version: 3.12.5, Platform: Linux-6.10.14-linuxkit-aarch64-with-glibc2.36
[2025-11-22T22:29:35.996+0000] {connection.py:1196} INFO - Connecting to GLOBAL Snowflake domain
[2025-11-22T22:29:35.996+0000] {connection.py:1277} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2025-11-22T22:29:36.459+0000] {cursor.py:1156} INFO - Number of results in first chunk: 1
[2025-11-22T22:29:36.460+0000] {sql.py:509} INFO - Running statement: select count(*) from (select SYMBOL, DATE from "USER_DB_OSTRICH"."RAW"."MARKET_DATA" group by 1,2 having count(*) > 1) having count(*) = 0, parameters: None
[2025-11-22T22:29:36.837+0000] {cursor.py:1156} INFO - Number of results in first chunk: 1
[2025-11-22T22:29:36.837+0000] {sql.py:518} INFO - Rows affected: 1
[2025-11-22T22:29:36.838+0000] {snowflake.py:422} INFO - Rows affected: 1
[2025-11-22T22:29:36.838+0000] {snowflake.py:423} INFO - Snowflake query id: 01c09205-0307-1b85-000f-c0df008b3946
[2025-11-22T22:29:36.902+0000] {cursor.py:1156} INFO - Number of results in first chunk: 1
[2025-11-22T22:29:36.902+0000] {connection.py:788} INFO - closed
[2025-11-22T22:29:36.948+0000] {connection.py:794} INFO - No async queries seem to be running, deleting session
[2025-11-22T22:29:37.036+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-11-22T22:29:37.037+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=market_data_ingest, task_id=dq_no_dupes, run_id=scheduled__2025-11-21T02:30:00+00:00, execution_date=20251121T023000, start_date=20251122T222935, end_date=20251122T222937
[2025-11-22T22:29:37.072+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-11-22T22:29:37.080+0000] {taskinstance.py:3900} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-11-22T22:29:37.080+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
